{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e9b63825-5b10-4354-8c95-36ce9facda05",
   "metadata": {},
   "source": [
    "Team 10 NLP Project\n",
    "\n",
    "Dataset: One Million Post Corpus\n",
    "Dataset Language: German\n",
    "\n",
    "Goal: Classify and predict User-Post catgeory\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee76977c-59d5-4f2f-a8ea-4804cfbc5f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "################### Create Posts_Annotated ###################\n",
    "##############################################################\n",
    "import sqlite3\n",
    "\n",
    "def getData(db_name):\n",
    "    # open and (if not exists) create database file\n",
    "    con = sqlite3.connect(db_name)\n",
    "    cur = con.cursor()\n",
    "\n",
    "    # create table\n",
    "    cur.execute(\"CREATE TABLE IF NOT EXISTS Posts_Annotated (\" +\n",
    "                \"ID_Post           INTEGER PRIMARY KEY,\" +\n",
    "                \"Status            INTEGER,\" +\n",
    "                \"Headline          TEXT,\" +\n",
    "                \"Body              TEXT,\" +\n",
    "                \"PositiveVotes     INTEGER,\" +\n",
    "                \"NegativeVotes     INTEGER,\" +\n",
    "                \"ArgumentsUsed     INTEGER,\" +\n",
    "                \"Discriminating    INTEGER,\" +\n",
    "                \"Inappropriate     INTEGER,\" +\n",
    "                \"OffTopic          INTEGER,\" +\n",
    "                \"PersonalStories   INTEGER,\" +\n",
    "                \"PossiblyFeedback  INTEGER,\" +\n",
    "                \"SentimentNegative INTEGER,\" +\n",
    "                \"SentimentNeutral  INTEGER,\" +\n",
    "                \"SentimentPositive INTEGER\" +\n",
    "                \");\")\n",
    "    \n",
    "    # check if we need to add data\n",
    "    cur.execute('SELECT Count(*) FROM Posts_Annotated')\n",
    "    count = cur.fetchall()\n",
    "    if(count[0][0] > 1):\n",
    "        return\n",
    "\n",
    "    # insert statement\n",
    "    insert_table = \"INSERT INTO Posts_Annotated ( ID_Post, Status, Headline, Body, PositiveVotes, NegativeVotes, ArgumentsUsed, Discriminating, Inappropriate, OffTopic, PersonalStories, PossiblyFeedback, SentimentNegative, SentimentNeutral, SentimentPositive ) values ( ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ? )\"\n",
    "\n",
    "    # select annotation\n",
    "    get_annotation = \"SELECT Category, Value FROM Annotations_consolidated WHERE ID_Post = ? ORDER BY Category\"\n",
    "    \n",
    "    # get all posts we need\n",
    "    cur.execute('SELECT ID_Post, ' +\n",
    "                'Status, ' +\n",
    "                'Headline, ' +\n",
    "                'Body, ' +\n",
    "                'PositiveVotes, ' +\n",
    "                'NegativeVotes ' +\n",
    "                'FROM Posts ' +\n",
    "                'WHERE ID_Post IN ( ' +\n",
    "                'SELECT ID_Post ' +\n",
    "                'FROM Annotations_consolidated);')\n",
    "\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    for row in rows:\n",
    "        next_row = []\n",
    "\n",
    "        for row_data in row:\n",
    "            next_row.append(row_data)\n",
    "\n",
    "        # get annotations\n",
    "        cur.execute(get_annotation, [row[0]])\n",
    "        annotations = cur.fetchall()\n",
    "        \n",
    "        types = [ \"ArgumentsUsed\", \"Discriminating\", \"Inappropriate\", \"OffTopic\", \"PersonalStories\", \"PossiblyFeedback\", \"SentimentNegative\", \"SentimentNeutral\", \"SentimentPositive\" ]\n",
    "        i = 0\n",
    "        for annotation in annotations:\n",
    "            while i < 9:\n",
    "                if types[i] in annotation[0]:\n",
    "                    next_row.append(annotation[1])\n",
    "                    i += 1\n",
    "                    break\n",
    "                else:\n",
    "                    next_row.append(-1)\n",
    "                    i += 1\n",
    "        \n",
    "        if i < 9:\n",
    "            while i < 9:\n",
    "                next_row.append(-1)\n",
    "                i += 1\n",
    "\n",
    "        cur.execute(insert_table, next_row)\n",
    "\n",
    "    # Save (commit) the changes\n",
    "    con.commit()\n",
    "\n",
    "    # close the database connection\n",
    "    con.close()\n",
    "\n",
    "getData(\"corpus.sqlite3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c56932-3ef2-4be4-8870-d877adc43515",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "############## Create Posts_Annotated_combined ###############\n",
    "##############################################################\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from spacy.attrs import LOWER, POS, ENT_TYPE, IS_ALPHA\n",
    "from spacy.tokens import Doc\n",
    "\n",
    "def remove_punct_and_numbers(corpus):\n",
    "    #code from https://stackoverflow.com/questions/45375488/how-to-filter-tokens-from-spacy-document\n",
    "    global nlp\n",
    "    indexes = []\n",
    "    doc = nlp(corpus)\n",
    "    for index, token in enumerate(doc):\n",
    "        if (token.pos_  in ('PUNCT', 'NUM', 'SYM')):\n",
    "            indexes.append(index)\n",
    "    np_array = doc.to_array([LOWER, POS, ENT_TYPE, IS_ALPHA])\n",
    "    np_array = np.delete(np_array, indexes, axis = 0)\n",
    "    doc2 = Doc(doc.vocab, words=[t.text for i, t in enumerate(doc) if i not in indexes])\n",
    "    doc2.from_array([LOWER, POS, ENT_TYPE, IS_ALPHA], np_array)\n",
    "    return doc2\n",
    "\n",
    "def combine_text(headline, body):\n",
    "    if(headline is None):\n",
    "        if(body is None):\n",
    "            return \"\"\n",
    "        else:\n",
    "            return \"\".join(token.text_with_ws for token in remove_punct_and_numbers(body))\n",
    "    else:\n",
    "        if(body is None):\n",
    "            return \"\".join(token.text_with_ws for token in remove_punct_and_numbers(headline))\n",
    "        else:\n",
    "            #drei pünktchen entfernen und text ohne punkt \n",
    "            if headline[-3:] == \"...\":\n",
    "                headline = headline[:-3]\n",
    "            if body[:3] == \"...\":\n",
    "                body = body[3:]\n",
    "            #alternativ auch manchmal zwei pünktchen\n",
    "            if headline[-3:] == \"..\":\n",
    "                headline = headline[:-3]\n",
    "            if body[:3] == \"..\":\n",
    "                body = body[3:]\n",
    "            \n",
    "            #add missing space, to avoid combining words\n",
    "            if headline[-1:] != \" \":\n",
    "                if body[:1] != \" \":\n",
    "                    headline += \" \"\n",
    "            else:\n",
    "                if body[:1] == \" \":\n",
    "                    body = body[1:]\n",
    "                    \n",
    "            return \"\".join(token.text_with_ws for token in remove_punct_and_numbers(headline + body))\n",
    "\n",
    "con = sqlite3.connect('corpus.sqlite3')\n",
    "Posts_Annotated_df = pd.read_sql_query(\"SELECT * FROM Posts_Annotated\", con)\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "Posts_Annotated_df.insert(2, \"combined_text\", Posts_Annotated_df.apply(lambda x: combine_text(x[\"Headline\"], x[\"Body\"]), axis=1))\n",
    "Posts_Annotated_df.drop(columns=['Headline', 'Body'], inplace=True)\n",
    "Posts_Annotated_df.to_sql(\"Posts_Annotated_combined\", con, if_exists='fail')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00c20c7-fb60-4a96-8f7e-0629c04a35a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "################# Create Dataframe for Test ##################\n",
    "##############################################################\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "\n",
    "con = sqlite3.connect('corpus.sqlite3')\n",
    "Posts_Annotated_df = pd.read_sql_query(\"SELECT * FROM Posts_Annotated_combined WHERE ID_Post IN (SELECT ID_Post FROM Posts_Annotated)\", con)\n",
    "nlp = spacy.load(\"de_core_news_lg\")\n",
    "shape = nlp(\"test\")\n",
    "\n",
    "#create vector representation for all inputs\n",
    "# Posts\n",
    "combined_text = np.empty((len(Posts_Annotated_df[\"combined_text\"]), shape.vector.shape[0]))\n",
    "pos = 0\n",
    "for text in Posts_Annotated_df[\"combined_text\"]:\n",
    "    combined_text[pos] = nlp(text).vector\n",
    "    pos += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b431942e-fb62-4089-ac2a-181c47f8a7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "################# Classifier Parameter Test ##################\n",
    "##############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "        \n",
    "def trainModel(text_vector, label, act=\"relu\", solv=\"adam\", l_rate=\"constant\", l_rate_init=0.001, mom=0.9, iter_change=10):\n",
    "    text_train, text_test, label_train, label_test = train_test_split(text_vector, label, test_size=0.30, random_state=101, shuffle=True)\n",
    "\n",
    "    # Model Training (MLPClassifier)\n",
    "    mlp_classifier = MLPClassifier(random_state=1, max_iter=5000, activation=act, solver=solv, learning_rate=l_rate, learning_rate_init=l_rate_init, momentum=mom, n_iter_no_change=iter_change) #increase iter\n",
    "    mlp_classifier.fit(text_train, label_train)\n",
    "\n",
    "    # Testing\n",
    "    model_predictions = mlp_classifier.predict(text_test)\n",
    "\n",
    "    # Evaluation\n",
    "    print(\"Accuracy:\", metrics.accuracy_score(label_test.to_numpy(), model_predictions) * 100)\n",
    "    print(\"Recall:\", metrics.recall_score(label_test.to_numpy(), model_predictions, average=\"binary\", pos_label=1) * 100)\n",
    "    print(\"Precision:\", metrics.precision_score(label_test.to_numpy(), model_predictions, average=\"binary\", pos_label=1) * 100)\n",
    "    print(\"F1-Score:\", metrics.f1_score(label_test.to_numpy(), model_predictions, average=\"binary\", pos_label=1) * 100)\n",
    "    print(\"Confusion Matrix:\", metrics.confusion_matrix(label_test.to_numpy(), model_predictions))\n",
    "\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"identity\", \"lbfgs\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"identity\", \"sgd\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"identity\", \"adam\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"logistic\", \"lbfgs\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"logistic\", \"sgd\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"logistic\", \"adam\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"tanh\", \"lbfgs\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"tanh\", \"sgd\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"tanh\", \"adam\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"lbfgs\")\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.001) #76,667\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.002) #76,389\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.003) #77,685\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.01) #77,314\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.02) #76,203\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.03) #76,667\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.1) #76,296\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.2) #73,703\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"constant\", 0.3) #73,703\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.001) #65,462\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.002) #68,056\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.003) #70,277\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.01) #75,556\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.02) #76,203\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.03) #76,389\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.1) #77,592\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.2) #76,389\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"invscaling\", 0.3) #74,444\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.001) #76,667\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.002) #76,574\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.003) #77,5\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.01) #77,685\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.02) #76,296\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.03) #76,111\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.04) #76,203\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.05) #77,96\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06) #77,96\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.1) #76,389\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.2) #76,481\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.3) #76,481\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.4) #77,870\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.5) #76,389\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.6) #75,833\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.7) #76,944\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.8) #76,759\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9) #77,962\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 11) #77,962\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 15) #78,240\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20) #78,240 <=== best\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 50) #78,240\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 100) #78,240\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.07) #77,129\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.08) #76,296\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.09) #77,037\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.1) #77,777\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.11) #75,277\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.2) #73,703\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"sgd\", \"adaptive\", 0.3) #71,389\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"relu\", \"adam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4798e9ad-44de-4ea4-a84a-8ff738b83047",
   "metadata": {},
   "outputs": [],
   "source": [
    "##############################################################\n",
    "#################### Test Classification #####################\n",
    "##############################################################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "        \n",
    "def trainModel(text_vector, label, label_name, sampling=\"n\", act=\"relu\", solv=\"adam\", l_rate=\"constant\", l_rate_init=0.001, mom=0.9, iter_change=10):\n",
    "    # split data\n",
    "    text_train, text_test, label_train, label_test = train_test_split(text_vector, label, test_size=0.30, random_state=101, shuffle=True)\n",
    "    \n",
    "    if sampling == \"o\":\n",
    "        model_name = \"MLPClassifier | Oversample\"\n",
    "        oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "        text_train, label_train = oversample.fit_resample(text_train, label_train)\n",
    "    elif sampling == \"u\":\n",
    "        model_name = \"MLPClassifier | Undersample\"\n",
    "        undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "        text_train, label_train = undersample.fit_resample(text_train, label_train)\n",
    "    else:\n",
    "        model_name = \"MLPClassifier\"\n",
    "    \n",
    "    # Model Training (MLPClassifier)\n",
    "    mlp_classifier = MLPClassifier(random_state=1, max_iter=5000, activation=act, solver=solv, learning_rate=l_rate, learning_rate_init=l_rate_init, momentum=mom, n_iter_no_change=iter_change) #increase iter\n",
    "    mlp_classifier.fit(text_train, label_train)\n",
    "\n",
    "    # Testing\n",
    "    model_predictions = mlp_classifier.predict(text_test)\n",
    "\n",
    "    # Evaluation\n",
    "    count_of_labels = label_train.copy()\n",
    "    count_of_labels = count_of_labels.append(label_test)\n",
    "    val_counts = count_of_labels.value_counts()\n",
    "    \n",
    "    fig, (ax1,ax2,ax3) = plt.subplots(1, 3)\n",
    "    fig.suptitle((\"Label: {}; Model: {}\".format(label_name, model_name)))\n",
    "    classifier_evaluation = (\"F1_Score: \" + str(metrics.f1_score(label_test, model_predictions)) + \"\\n\" +\n",
    "                             \"Accuracy: \" + str(metrics.accuracy_score(label_test, model_predictions)) + \"\\n\" +\n",
    "                             \"Precision: \" + str(metrics.precision_score(label_test, model_predictions)) + \"\\n\" +\n",
    "                             \"Recall: \" + str(metrics.recall_score(label_test, model_predictions)) + \"\\n\" +\n",
    "                             \"Instances of value 0: \" + str(val_counts[0]) + \"\\n\" +\n",
    "                             \"Instances of value 1: \" + str(val_counts[1]))\n",
    "    plt.figtext(0.99, 0.01, classifier_evaluation, horizontalalignment='left', verticalalignment=\"bottom\", fontsize=15)\n",
    "    conf_matrix_normalized = ConfusionMatrixDisplay.from_predictions(label_test, model_predictions, normalize=\"true\", ax=ax1)\n",
    "    conf_matrix = ConfusionMatrixDisplay.from_predictions(label_test, model_predictions, ax=ax2)\n",
    "    bar_plot = val_counts.plot.bar(ax=ax3, title = \"Verteilung des Labels\")\n",
    "    fig.tight_layout()\n",
    "    label_name = label_name.replace(\" | \", \"_\")\n",
    "    label_name = label_name.replace(\"/\", \"_\")\n",
    "    model_name = model_name.replace(\" | \", \"_\")\n",
    "    fig.savefig(label_name + \"_\" + model_name + \".pdf\", bbox_inches='tight')\n",
    "    plt.close(fig)\n",
    "\n",
    "#add up and downvotes\n",
    "combined_text_2 = combined_text.copy()\n",
    "combined_text_2 = np.pad(combined_text_2, ((0,0),(0,2)), 'constant')\n",
    "for x, vec in enumerate(combined_text_2):\n",
    "    vec[-2] = Posts_Annotated_df[\"PositiveVotes\"][x]\n",
    "    vec[-1] = Posts_Annotated_df[\"NegativeVotes\"][x]\n",
    "\n",
    "#add status\n",
    "combined_text_3 = combined_text.copy()\n",
    "combined_text_3 = np.pad(combined_text_3, ((0,0),(0,1)), 'constant')\n",
    "for x, vec in enumerate(combined_text_3):\n",
    "    status = Posts_Annotated_df[\"Status\"][x]\n",
    "    if \"online\" in status:\n",
    "        vec[-1] = 1\n",
    "    elif \"deleted\" in status:\n",
    "        vec[-1] = 0\n",
    "    else:\n",
    "        vec[-1] = 99\n",
    "        print(\"There was no status\")\n",
    "\n",
    "#add up, downvotes and status\n",
    "combined_text_4 = combined_text.copy()\n",
    "combined_text_4 = np.pad(combined_text_4, ((0,0),(0,3)), 'constant')\n",
    "for x, vec in enumerate(combined_text_4):\n",
    "    vec[-3] = Posts_Annotated_df[\"PositiveVotes\"][x]\n",
    "    vec[-2] = Posts_Annotated_df[\"NegativeVotes\"][x]\n",
    "    status = Posts_Annotated_df[\"Status\"][x]\n",
    "    if \"online\" in status:\n",
    "        vec[-1] = 1\n",
    "    elif \"deleted\" in status:\n",
    "        vec[-1] = 0\n",
    "    else:\n",
    "        vec[-1] = 99\n",
    "        print(\"There was no status\")\n",
    "\n",
    "# Copy data\n",
    "ArgumentsUsedText = combined_text_2.copy()\n",
    "ArgumentsUsedDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in ArgumentsUsedDF.iterrows():\n",
    "    if row[1][\"ArgumentsUsed\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "ArgumentsUsedText = np.delete(ArgumentsUsedText, index_to_delete, 0)\n",
    "ArgumentsUsedDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"ArgumentsUsed\"], \"ArgumentsUsed\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(ArgumentsUsedText, ArgumentsUsedDF[\"ArgumentsUsed\"], \"ArgumentsUsed | Votes\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(ArgumentsUsedText, ArgumentsUsedDF[\"ArgumentsUsed\"], \"ArgumentsUsed | Votes\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(ArgumentsUsedText, ArgumentsUsedDF[\"ArgumentsUsed\"], \"ArgumentsUsed | Votes\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_3, Posts_Annotated_df[\"ArgumentsUsed\"], \"ArgumentsUsed | Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_4, Posts_Annotated_df[\"ArgumentsUsed\"], \"ArgumentsUsed | Votes/Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Used already before all known data\n",
    "\n",
    "\n",
    "# Copy data\n",
    "DiscriminatingText = combined_text_3.copy()\n",
    "DiscriminatingDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in DiscriminatingDF.iterrows():\n",
    "    if row[1][\"Discriminating\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "DiscriminatingText = np.delete(DiscriminatingText, index_to_delete, 0)\n",
    "DiscriminatingDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"Discriminating\"], \"Discriminating\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_2, Posts_Annotated_df[\"Discriminating\"], \"Discriminating | Votes\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(DiscriminatingText, DiscriminatingDF[\"Discriminating\"], \"Discriminating | Status\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(DiscriminatingText, DiscriminatingDF[\"Discriminating\"], \"Discriminating | Status\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(DiscriminatingText, DiscriminatingDF[\"Discriminating\"], \"Discriminating | Status\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_4, Posts_Annotated_df[\"Discriminating\"], \"Discriminating | Votes/Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Used already before all known data\n",
    "\n",
    "\n",
    "# Copy data\n",
    "InappropriateText = combined_text_4.copy()\n",
    "InappropriateDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in InappropriateDF.iterrows():\n",
    "    if row[1][\"Inappropriate\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "InappropriateText = np.delete(InappropriateText, index_to_delete, 0)\n",
    "InappropriateDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"Inappropriate\"], \"Inappropriate\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_2, Posts_Annotated_df[\"Inappropriate\"], \"Inappropriate | Votes\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_3, Posts_Annotated_df[\"Inappropriate\"], \"Inappropriate | Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(InappropriateText, InappropriateDF[\"Inappropriate\"], \"Inappropriate | Votes/Status\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(InappropriateText, InappropriateDF[\"Inappropriate\"], \"Inappropriate | Votes/Status\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(InappropriateText, InappropriateDF[\"Inappropriate\"], \"Inappropriate | Votes/Status\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Used already before all known data\n",
    "\n",
    "\n",
    "# Copy data\n",
    "OffTopicText = combined_text_3.copy()\n",
    "OffTopicDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in OffTopicDF.iterrows():\n",
    "    if row[1][\"OffTopic\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "OffTopicText = np.delete(OffTopicText, index_to_delete, 0)\n",
    "OffTopicDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"OffTopic\"], \"OffTopic\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_2, Posts_Annotated_df[\"OffTopic\"], \"OffTopic | Votes\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(OffTopicText, OffTopicDF[\"OffTopic\"], \"OffTopic | Status\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(OffTopicText, OffTopicDF[\"OffTopic\"], \"OffTopic | Status\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(OffTopicText, OffTopicDF[\"OffTopic\"], \"OffTopic | Status\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_4, Posts_Annotated_df[\"OffTopic\"], \"OffTopic | Votes/Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Used already before all known data\n",
    "\n",
    "\n",
    "# Copy data\n",
    "PersonalStoriesText = combined_text_3.copy()\n",
    "PersonalStoriesDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in PersonalStoriesDF.iterrows():\n",
    "    if row[1][\"PersonalStories\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "PersonalStoriesText = np.delete(PersonalStoriesText, index_to_delete, 0)\n",
    "PersonalStoriesDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "##trainModel(combined_text, Posts_Annotated_df[\"PersonalStories\"], \"PersonalStories\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_2, Posts_Annotated_df[\"PersonalStories\"], \"PersonalStories | Votes\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(PersonalStoriesText, PersonalStoriesDF[\"PersonalStories\"], \"PersonalStories | Status\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(PersonalStoriesText, PersonalStoriesDF[\"PersonalStories\"], \"PersonalStories | Status\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(PersonalStoriesText, PersonalStoriesDF[\"PersonalStories\"], \"PersonalStories | Status\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_4, Posts_Annotated_df[\"PersonalStories\"], \"PersonalStories | Votes/Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Has improved a lot with more data\n",
    "\n",
    "\n",
    "# Copy data\n",
    "PossiblyFeedbackText = combined_text_2.copy()\n",
    "PossiblyFeedbackDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in PossiblyFeedbackDF.iterrows():\n",
    "    if row[1][\"PossiblyFeedback\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "PossiblyFeedbackText = np.delete(PossiblyFeedbackText, index_to_delete, 0)\n",
    "PossiblyFeedbackDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"PossiblyFeedback\"], \"PossiblyFeedback\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(PossiblyFeedbackText, PossiblyFeedbackDF[\"PossiblyFeedback\"], \"PossiblyFeedback | Votes\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(PossiblyFeedbackText, PossiblyFeedbackDF[\"PossiblyFeedback\"], \"PossiblyFeedback | Votes\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(PossiblyFeedbackText, PossiblyFeedbackDF[\"PossiblyFeedback\"], \"PossiblyFeedback | Votes\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_3, Posts_Annotated_df[\"PossiblyFeedback\"], \"PossiblyFeedback | Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_4, Posts_Annotated_df[\"PossiblyFeedback\"], \"PossiblyFeedback | Votes/Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Has improved a lot with more data\n",
    "\n",
    "\n",
    "# Copy data\n",
    "SentimentNegativeText = combined_text_3.copy()\n",
    "SentimentNegativeDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in SentimentNegativeDF.iterrows():\n",
    "    if row[1][\"SentimentNegative\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "SentimentNegativeText = np.delete(SentimentNegativeText, index_to_delete, 0)\n",
    "SentimentNegativeDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"SentimentNegative\"], \"SentimentNegative\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_2, Posts_Annotated_df[\"SentimentNegative\"], \"SentimentNegative | Votes\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(SentimentNegativeText, SentimentNegativeDF[\"SentimentNegative\"], \"SentimentNegative | Status\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(SentimentNegativeText, SentimentNegativeDF[\"SentimentNegative\"], \"SentimentNegative | Status\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(SentimentNegativeText, SentimentNegativeDF[\"SentimentNegative\"], \"SentimentNegative | Status\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_4, Posts_Annotated_df[\"SentimentNegative\"], \"SentimentNegative | Votes/Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Used already before all known data\n",
    "\n",
    "\n",
    "# Copy data\n",
    "SentimentNeutralText = combined_text_4.copy()\n",
    "SentimentNeutralDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in SentimentNeutralDF.iterrows():\n",
    "    if row[1][\"SentimentNeutral\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "SentimentNeutralText = np.delete(SentimentNeutralText, index_to_delete, 0)\n",
    "SentimentNeutralDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"SentimentNeutral\"], \"SentimentNeutral\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_2, Posts_Annotated_df[\"SentimentNeutral\"], \"SentimentNeutral | Votes\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_3, Posts_Annotated_df[\"SentimentNeutral\"], \"SentimentNeutral | Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(SentimentNeutralText, SentimentNeutralDF[\"SentimentNeutral\"], \"SentimentNeutral | Votes/Status\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(SentimentNeutralText, SentimentNeutralDF[\"SentimentNeutral\"], \"SentimentNeutral | Votes/Status\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(SentimentNeutralText, SentimentNeutralDF[\"SentimentNeutral\"], \"SentimentNeutral | Votes/Status\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Used already before all known data\n",
    "\n",
    "\n",
    "# Copy data\n",
    "SentimentPositiveText = combined_text_2.copy()\n",
    "SentimentPositiveDF = Posts_Annotated_df.copy()\n",
    "\n",
    "# Get indecies to delete\n",
    "index_to_delete = []\n",
    "for row in SentimentPositiveDF.iterrows():\n",
    "    if row[1][\"SentimentPositive\"] == -1:\n",
    "        index_to_delete.append(row[0])\n",
    "\n",
    "# Delete indecies\n",
    "SentimentPositiveText = np.delete(SentimentPositiveText, index_to_delete, 0)\n",
    "SentimentPositiveDF.drop(index_to_delete, axis=0, inplace=True)\n",
    "\n",
    "# Train and test Model\n",
    "#trainModel(combined_text, Posts_Annotated_df[\"SentimentPositive\"], \"SentimentPositive\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(SentimentPositiveText, SentimentPositiveDF[\"SentimentPositive\"], \"SentimentPositive | Votes\", \"n\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(SentimentPositiveText, SentimentPositiveDF[\"SentimentPositive\"], \"SentimentPositive | Votes\", \"o\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "trainModel(SentimentPositiveText, SentimentPositiveDF[\"SentimentPositive\"], \"SentimentPositive | Votes\", \"u\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_3, Posts_Annotated_df[\"SentimentPositive\"], \"SentimentPositive | Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "#trainModel(combined_text_4, Posts_Annotated_df[\"SentimentPositive\"], \"SentimentPositive | Votes/Status\", \"relu\", \"sgd\", \"adaptive\", 0.06, 0.9, 20)\n",
    "# Used already before all known data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
